2015-06-03

Went to CMU health center and then to MedExpress, got an x-ray of my foot. Came to office around 10:20.

Wed, 03 Jun 2015 11:19:59

Installed Caffe on my laptop at `/home/praveen/programs/caffe/build`
Did `make runtest` it failed wit the following error:

```
[----------] 1 test from SolverTest/2, where TypeParam = caffe::FloatGPU
[ RUN      ] SolverTest/2.TestInitTrainTestNets
[       OK ] SolverTest/2.TestInitTrainTestNets (0 ms)
[----------] 1 test from SolverTest/2 (0 ms total)

[----------] 2 tests from SoftmaxLayerTest/3, where TypeParam = caffe::DoubleGPU
[ RUN      ] SoftmaxLayerTest/3.TestGradient
F0603 11:18:33.837002 14902 syncedmem.cpp:57] Check failed: error == cudaSuccess (35 vs. 0)  CUDA driver version is insufficient for CUDA runtime version
*** Check failure stack trace: ***
    @     0x2b367791dfad  google::LogMessage::Fail()
    @     0x2b367791ff28  google::LogMessage::SendToLog()
    @     0x2b367791db43  google::LogMessage::Flush()
    @     0x2b367792085e  google::LogMessageFatal::~LogMessageFatal()
    @     0x2b367715305c  caffe::SyncedMemory::gpu_data()
    @     0x2b3677154a22  caffe::Blob<>::gpu_data()
    @     0x2b3677274cd5  caffe::SoftmaxLayer<>::Forward_gpu()
    @           0x6a8fe8  caffe::Layer<>::Forward()
    @           0x6af4e2  caffe::GradientChecker<>::CheckGradientSingle()
    @           0x6b4863  caffe::GradientChecker<>::CheckGradientExhaustive()
    @           0x72f78f  caffe::SoftmaxLayerTest_TestGradient_Test<>::TestBody()
    @           0x9b8ce3  testing::internal::HandleExceptionsInMethodIfSupported<>()
    @           0x9af507  testing::Test::Run()
    @           0x9af5ae  testing::TestInfo::Run()
    @           0x9af6b5  testing::TestCase::Run(
    @           0x9b2408  testing::internal::UnitTestImpl::RunAllTests()
    @           0x9b26a7  testing::UnitTest::Run()
    @           0x6914ca  main
    @     0x2b367d2e3ec5  __libc_start_main
    @           0x6961b2  (unknown)
Aborted (core dumped)
make[3]: *** [src/caffe/test/CMakeFiles/runtest] Error 134
make[2]: *** [src/caffe/test/CMakeFiles/runtest.dir/all] Error 2
make[1]: *** [src/caffe/test/CMakeFiles/runtest.dir/rule] Error 2
make: *** [runtest] Error 2
praveen@praveen-Inspiron-7537:~/programs/caffe/build$ 

```

================================

Decided to get started with Caffe on the Jetson instead of spending time to make it work on my laptop. Followed the imagenet classification example: <http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/classification.ipynb>
`import caffe` landed me in few errors. But I solved them all by installing the missing dependencies like `sudo pip install protobuf` , scikitimage, numpy etc.



Wed, 03 Jun 2015 16:54:03
====================================
Stumbled upon the magic functions in Ipython while reading the imagenet tutorial at caffe's page.
<https://ipython.org/ipython-doc/dev/interactive/tutorial.html>
Tempted to install Ipython. `%timeit COMMAND/CALL_HERE` seems pretty nice!


Wed, 03 Jun 2015

Wed, 03 Jun 2015 20:12:53
 16:58:21

Started wondering why I am using markdown for my diary instead of Ipython?!

Wed, 03 Jun 2015 17:36:07
===================

Used the caffenet ,**bvlc_reference_caffenet.caffemodel** and the **imagenet's ilsvrc_2012_mean.npy** to classify the `caffe/examples/images/cat.jpg`. 

When run on the jetson with `caffe.set_mode_cpu()` the `%timeit net.predict([input_image])` resulted in: `1 loops, best of 3: 9.25 s per loop ` !.
(Yes! I have started using ipython).

Next, I did `caffe.set_mode_gpu()` and then did `%timeit net.predict([input_image])` it resulted in:
`1 loops, best of 3: 585 ms per loop`

Which is 9250/585=15 times faster!

Wed, 03 Jun 2015 20:12:53
TODO: copy paste the things that happend from nvidiaLaptopWiki.md from jetson

`xrandr` gave the following output:
```
praveen@praveen-Inspiron-7537:~$ xrandr
Screen 0: minimum 8 x 8, current 864 x 486, maximum 32767 x 32767
eDP1 connected primary 864x486+0+0 (normal left inverted right x axis y axis) 344mm x 193mm
   864x486        60.0* 
   640x480        59.9  
HDMI1 disconnected (normal left inverted right x axis y axis)
VIRTUAL1 disconnected (normal left inverted right x axis y axis)
```

WOW! I was long been wondering why my maximum resolution is only HD (1920x 1080) when the Apple Mac book pro retina with the same Nvidia Gt 750m has a much higher resolution (2xxxX 2xxx something). But then when I read `32767X 32767` I realized that its the maximum int val and I doubt a display can support that resolution.

My scrollpad's direction has changed!

Wed, 03 Jun 2015 20:18:15

I tried `xrandr --output eDP1 --mode 1920x1080` it said `cannot find mode 1920x1080`




Wed, 03 Jun 2015 21:17:42

Can you believe this??!
```
praveen@praveen-Inspiron-7537:~/cuda/NVIDIA_CUDA-7.0_Samples/1_Utilities/deviceQueryDrv$ ./deviceQueryDrv 
./deviceQueryDrv Starting...

CUDA Device Query (Driver API) statically linked version 
Detected 1 CUDA Capable device(s)

Device 0: "GeForce GT 750M"
  CUDA Driver Version:                           7.0
  CUDA Capability Major/Minor version number:    3.0
  Total amount of global memory:                 2048 MBytes (2147352576 bytes)
  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores
  GPU Max Clock rate:                            967 MHz (0.97 GHz)
  Memory Clock rate:                             2005 Mhz
  Memory Bus Width:                              128-bit
  L2 Cache Size:                                 262144 bytes
  Max Texture Dimension Sizes                    1D=(65536) 2D=(65536, 65536) 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size (x,y,z):    (2147483647, 65535, 65535)
  Texture alignment:                             512 bytes
  Maximum memory pitch:                          2147483647 bytes
  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Concurrent kernel execution:                   Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 4 / 0
  Compute Mode:
     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >
Result = PASS
```
Although `optirun nvidia-settings` results in: 

```
 praveen@praveen-Inspiron-7537:~/cuda/NVIDIA_CUDA-7.0_Samples$ optirun nvidia-settings 
[ 1833.339789] [ERROR]Cannot access secondary GPU - error: [XORG] (EE) [drm] KMS not enabled

[ 1833.339828] [ERROR]Aborting because fallback start is disabled.
```

FInally, the CUDA samples are running fine!!!

```
praveen@praveen-Inspiron-7537:~/cuda/NVIDIA_CUDA-7.0_Samples/1_Utilities/deviceQuery$ ./deviceQuery 
./deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: "GeForce GT 750M"
  CUDA Driver Version / Runtime Version          7.0 / 7.0
  CUDA Capability Major/Minor version number:    3.0
  Total amount of global memory:                 2048 MBytes (2147352576 bytes)
  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores
  GPU Max Clock rate:                            967 MHz (0.97 GHz)
  Memory Clock rate:                             2005 Mhz
  Memory Bus Width:                              128-bit
  L2 Cache Size:                                 262144 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
  Run time limit on kernels:                     No
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 4 / 0
  Compute Mode:
     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 7.0, CUDA Runtime Version = 7.0, NumDevs = 1, Device0 = GeForce GT 750M
Result = PASS
```

```
praveen@praveen-Inspiron-7537:~/cuda/NVIDIA_CUDA-7.0_Samples/1_Utilities/bandwidthTest$ ./bandwidthTest 
[CUDA Bandwidth Test] - Starting...
Running on...

 Device 0: GeForce GT 750M
 Quick Mode

 Host to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)    Bandwidth(MB/s)
   33554432         1527.1

 Device to Host Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)    Bandwidth(MB/s)
   33554432         1637.0

 Device to Device Bandwidth, 1 Device(s)
 PINNED Memory Transfers
   Transfer Size (Bytes)    Bandwidth(MB/s)
   33554432         45092.2

Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
```

```
praveen@praveen-Inspiron-7537:~/cuda/NVIDIA_CUDA-7.0_Samples/1_Utilities/bandwidthTest$ nvidia-smi 
Wed Jun  3 21:21:26 2015       
+------------------------------------------------------+                       
| NVIDIA-SMI 346.72     Driver Version: 346.72         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GT 750M     Off  | 0000:04:00.0     N/A |                  N/A |
| N/A   55C    P0    N/A /  N/A |      8MiB /  2047MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0            C+G   Not Supported                                         |
+-----------------------------------------------------------------------------+
```


Wed, 03 Jun 2015 21:57:06
**NOTE to my self**
I made a new build directory build_new under caffe/

Wed, 03 Jun 2015 22:22:03

Ran the same example :<http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/classification.ipynb> on my laptop:

with `caffe.set_mode_cpu()` ,
```
In [29]: %timeit net.predict([input_image])
1 loops, best of 3: 1.19 s per loop
```

```
In [30]: caffe.set_mode_gpu()

In [31]: %timeit net.predict([input_image])
1 loops, best of 3: 158 ms per loop
```

```
In [32]: # Resize the image to the standard (256, 256) and oversample net input sized crops.

In [33]: input_oversampled = caffe.io.oversample([caffe.io.resize_image(input_image, net.image_dims)], net.crop_dims)

In [34]: # 'data' is the input blob name in the model definition, so we preprocess for that input.

In [35]: caffe_input = np.asarray([net.transformer.preprocess('data', in_) for in_ in input_oversampled])

In [36]: # forward() takes keyword args for the input blobs with preprocessed input arrays.

In [37]: %timeit net.forward(data=caffe_input)
10 loops, best of 3: 124 ms per loop
```

```
In [38]: %timeit net.predict([input_image])
10 loops, best of 3: 159 ms per loop
```

