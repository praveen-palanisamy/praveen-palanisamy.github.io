# timeline section data
- timeline-item:
  date: March 26, 2021
  title: "[Guest Lecture @CMU] Deep Reinforcement Learning: Building Autonomous Agents"
  img: CMU-Kigali-talk-Twitter-01-768x433.jpg
  description: "Delivered a quick primer on Deep Reinforcement Learning and any interested and curious student can dive into the field using read-made recipes from the TFRL Cookbook. The talk also covers pointers to free book, lectures and courses available to build a strong foundation and theoretical understanding before embarking on a practical, application oriented journey using the relatively advanced recipes discussed in the TFRL Cookbook."
  link: CMU-kigali-talk-PRAVEEN-PALANISAMY-RL-Guest-Lecture-1024x677.jpg
  latest: true

- timeline-item:
  date: January 24, 2021
  title: "[Book Published] TensorFlow 2.x Reinforcement Learning Cookbook"
  img: tfrl-ckbk-cover-focused-768x447.jpg
  description: "A practical guide with 50 short-&-sweet recipes to help you build, train and deploy learning agents for real-world applications. Full blog-post"
  link: https://praveenp.com
  icon: fa-book

- timeline-itme:
  date: March 9, 2021
  title: "[Patent]Spatial and temporal attention-based deep reinforcement learning of hierarchical lane-change policies for controlling an autonomous vehicle"
  img: spatio-temporal-attention-hdrl-768x662.png
  description: "Performing safe and efficient lane changes is a crucial feature for creating fully autonomous vehicles. Recent advances have demonstrated successful lane following behavior using deep reinforcement learning, yet the interactions with other vehicles on road for lane changes are rarely considered. Systems and methods are provided that employ spatial and temporal attention-based deep reinforcement learning of hierarchical lane-change policies for controlling an autonomous vehicle. An actor-critic network architecture includes an actor network that process image data received from an environment to learn the lane-change policies as a set of hierarchical actions, and a critic network that evaluates the lane-change policies to calculate loss and gradients to predict an action-value function (Q) that is used to drive learning and update parameters of the lane-change policies. The actor-critic network architecture implements a spatial attention module to select relevant regions in the image data that are of importance, and a temporal attention module to learn temporal attention weights to be applied to past frames of image data to indicate relative importance in deciding which lane-change policy to select."
  link: https://patentimages.storage.googleapis.com/81/26/e7/5326f00f5c1501/US10940863.pdf

- timeline-item:
  date: November 21, 2020
  title: "Elevated to IEEE Senior Member"
  img: ieee-senior-member-plaque-768x626.jpeg

- timeline-item:
  date: July 24, 2020
  title: "[IJCNN20][Oral]Multi-Agent Deep RL for Connected Autonomous Driving"
  img: ijcnn-presentation-slide1-praveen-palanisamy-768x277.png
  description: "Excited to be part of IEEE World Congress on Computational Intelligence (WCCI) 2020. I will making an oral presentation at the International Joint Conference on Convolutional Neural Networks (IJCNN) Special Session on Methods and Applications of Deep Reinforcement Learning to Autonomous Systems. More info and link to presentation: https://2020.wcci-virtual.org/presentation/oral/multi-agent-connected-autonomous-driving-using-deep-reinforcement-learning"
  link: https://2020.wcci-virtual.org/presentation/oral/multi-agent-connected-autonomous-driving-using-deep-reinforcement-learning

- timeline-item:
  date: July 23, 2020
  title: "[Guest talk] Keynote presentation on RL for Smart Cities (AMSB2020)"
  img: amsb2020-768x137.png
  description: "Invited keynote speaker at the international virtual conference on AI & ML Applications in Smart Buildings (AMSB2020). Gave a talk on “Reinforcement Learning for Smart Cities”."
  link: https://chennai.vit.ac.in/events/international-virtual-conference-on-ai-and-ml-applications-in-smart-buildings-amsb2020/

- timeline-item:
  date: January 11, 2020
  title: "[Demo] CES 2020"
  img: ces-2020-2cities-360-768x314.jpeg
  description: "It was an invaluable CES 2020 experience as a part of Microsoft’s Autonomous Systems group collaborating with Bell Helicopter (https://lnkd.in/eGqndv9) in the showcase of Bell’s AerOS’s capabilities with a fully operational demo using scaled-down Nexus 4EX (https://lnkd.in/enJ5W5F) in a smart city. While it’s far from perfect, just seeing the TOL (Take-Off-Landing) and the NAV (Navigation) “Brains”, (providing an autonomous visual guidance system as a backup) deployed onto Bell’s drones that were demoed to the 150k+ CES audience was rewarding for me after months of hard-work on the AI pipeline. Thanks to Microsoft and Bell for providing the opportunity. This was my shortest development-to-deployment/production cycle of an autonomous (sub)system till date that was demoed publicly on the target hardware/robot!"

- timeline-item:
  date: December 8, 2019
  title: "[NeurIPS19] Multi-Agent Connected Autonomous Driving using Deep Reinforcement Learning "
  img: macad-gym-urban_4way_intrx_2c1p1m-768x182.png
  # TODO: Add NeurIPS img slideshow
  description: "The capability to learn and adapt to changes in the driving environment is crucial fordeveloping autonomous driving systems that are scalable beyond geo-fenced oper-ational design domains. Deep Reinforcement Learning (RL) provides a promisingand scalable framework for developing adaptive learning based solutions. Deep RLmethods usually model the problem as a (Partially Observable) Markov DecisionProcess in which an agent acts in a stationary environment to learn an optimalbehavior policy. However, driving involves complex interaction between multiple,intelligent (artificial or human) agents in a highly non-stationary environment. Inthis paper, we propose the use of Partially Observable Markov Games(POSG) forformulating the connected autonomous driving problems with realistic assumptions.We provide a taxonomy of multi-agent learning environments based on the natureof tasks, nature of agents and the nature of the environment to help in categorizingvarious autonomous driving problems that can be addressed under the proposedformulation. As our main contributions, we provide MACAD-Gym, a Multi-AgentConnected, Autonomous Driving agent learning platform for furthering research inthis direction. Our MACAD-Gym platform provides an extensible set of ConnectedAutonomous Driving (CAD) simulation environments that enable the research anddevelopment of Deep RL- based integrated sensing, perception, planning andcontrol algorithms for CAD systems with unlimited operational design domainunder realistic, multi-agent settings. We also share the MACAD-Agents that weretrained successfully using the MACAD-Gym platform to learn control policies formultiple vehicle agents in a partially observable, stop-sign controlled, 3-way urbanintersection environment with raw (camera) sensor observations. Paper: https://arxiv.org/abs/1911.04175  Code: https://github.com/praveen-palanisamy/macad-gym"
  link: https://github.com/praveen-palanisamy/macad-gym

- timeline-item:
  date: October 4, 2019
  title: "Winner at TechCrunch Disrupt San Francisco 2019 Hackathon"
  img: techcrunch-disrupt-2019-hackathon-winner-praveen-palanisamy-e1571028954348-768x827.jpg
  # TODO: Add TechCrunch Disrupt hackathon img slideshow
  description: "Built SaveWise- An AI powered fin-tech app that won the TechCrunch Disrupt San Francisco 2019 Hackathanon sponsored by Plaid.SaveWise is an AI service that connects to a user’s bank/card accounts, trains on their past transaction data and predicts upcoming expenses and savings potential for the future. It is aimed at helping users to pay down their debt faster and attain financial freedom. It provides pro-active, actionable notifications, for e.g.: It can predict when and where you will head out to grab lunch and provides you more economical options without changing your lifestyle (same cuisine etc.). Visit the project page for more info:  https://devpost.com/software/spendwise-69ik2c"
  link: https://devpost.com/software/spendwise-69ik2c

- timeline-item:
  date: September 22, 2019
  title: "Technical Program Committee Member, IEEE Connected Autonomous Vehicles Symposium, 2019"
  img: ieee-cavs-2019.png

- timeline-item:
  date: September 7, 2019
  title: "Received “Best Reinforcement Learning ebooks of all time” award!"
  img: best-reinforcement-learning-ebooks.png
  description: "I’m happy to announce that my book, HOIAWOG!  “Hands-On Intelligent Agents with OpenAI Gym: Your guide to developing AI agents using deep reinforcement learning”, made it to the <a href='https://bookauthority.org/books/best-reinforcement-learning-ebooks?t=1a0g37&s=award&book=178883657X'>Best Reinforcement Learning eBooks of All Time!</a> compiled by BookAuthority. BookAuthority collects and ranks the best books in the world, and it is a great honor to get this kind of recognition. Thank you for all the reader’s support! You can learn more about the HOIAWOG book here. The source code for all the agents, algorithms and implementation details are available on GitHub. You can get a copy of the book from Amazon."
  link: https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym

- timeline-item:
  date: June 17, 2019
  title: "Joined Microsoft as a Senior AI Engineer"
  img: ms-pp-768x576.jpg
  description: "Excited to join Microsoft’s Autonomous Systems, Business AI org as a Senior AI Engineer to work on developing end-to-end platform and services for real-world AI applications using Reinforcement Learning and Machine Teaching"

- timeline-item:
  date: June 16, 2019
  title: "[CVPR19]Attention-Based Hierarchical Deep Reinforcement Learning for Lane Change Behaviors in Autonomous Driving"
  img: attentionDDPG1.png
  description: "Performing safe and efficient lane changes is a crucial feature for creating fully autonomous vehicles. Recent advances have demonstrated successful lane following behavior using deep reinforcement learning, yet the interactions with other vehicles on road for lane changes are rarely considered. In this paper, we design a hierarchical Deep Reinforcement Learning (DRL) algorithm to learn lane change behaviors in dense traffic. By breaking down overall behavior to sub-policies, faster and safer lane change actions can be learned. We also apply temporal and spatial attention to the DRL architecture, which helps the vehicle focus more on surrounding vehicles and leads to smoother lane change behavior. We conduct our experiments in the TORCS simulator and the results outperform the state-of-art deep reinforcement learning algorithm in various lane change scenarios. Citing: Chen, Y., Dong, C., Palanisamy, P., Mudalige, P., Muelling, K., & Dolan, J. M. (2019). Attention-Based Hierarchical Deep Reinforcement Learning for Lane Change Behaviors in Autonomous Driving. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (pp. 0-0)."
  link: http://openaccess.thecvf.com/content_CVPRW_2019/papers/Autonomous%20Driving/Chen_Attention-Based_Hierarchical_Deep_Reinforcement_Learning_for_Lane_Change_Behaviors_in_CVPRW_2019_paper.pdf

- timeline-item:
  date: January 8, 2019
  title: "[WACV19]Learning On-Road Visual Control for Self-Driving Vehicles with Auxiliary Tasks"
  img: WACV19_learning_on-road_visual_nav_aux_tasks-768x566.png
  description: "A safe and robust on-road navigation system is a crucial component of achieving fully automated vehicles. NVIDIA recently proposed an End-to-End algorithm that can directly learn steering commands from raw pixels of a front camera by using one convolutional neural network. In this paper, we leverage auxiliary information aside from raw images and design a novel network structure, called Auxiliary Task Network (ATN), to help boost the driving performance while maintaining the advantage of minimal training data and an End-to-End training method. In this network, we introduce human prior knowledge into vehicle navigation by transferring features from image recognition tasks. Image semantic segmentation is applied as an auxiliary task for navigation. We consider temporal information by introducing an LSTM module and optical flow to the network. Finally, we combine vehicle kinematics with a sensor fusion step. We discuss the benefits of our method over state-of-the-art visual navigation methods both in the Udacity simulation environment and on the real-world Comma.ai dataset. Citing: Yilun Chen, Praveen Palanisamy, Priyantha Mudalige, Katharina Muelling: “Learning On-Road Visual Control for Self-Driving Vehicles with Auxiliary Tasks”, 2018; arXiv:1812.07760."
  link: https://arxiv.org/abs/1812.07760

- timeline-item:
  date: November 4, 2018
  title: "[ITSC18]POMDP and Hierarchical Options MDP with Continuous Actions for Autonomous Driving at Intersections"
  img: image-768x768.png
  description: "When applying autonomous driving technology to real-world scenarios, environmental uncertainties make the development of decision-making algorithms difficult. Modeling the problem as a Partially Observable Markov Decision Process (POMDP) [1] allows the algorithm to consider these uncertainties in the decision process, which makes it more robust to real sensor characteristics. However, solving the POMDP with reinforcement learning (RL) [2] often requires storing a large number of observations. Furthermore, for continuous action spaces, the system is computationally inefficient. This paper addresses these problems by proposing to model the problem as an MDP and learn a policy with RL using hierarchical options (HOMDP). The suggested algorithm can store the state-action pairs and only uses current observations to solve a POMDP problem. We compare the results of to the time-to-collision method [3] and the proposed POMDP-with-LSTM method. Our results show that the HOMDP approach is able to improve the performance of the agent for a four-way intersection task with two-way stop signs. The HOMDP method can generate both higher-level discrete options and lower-level continuous actions with only the observations of the current step. Citing: Z. Qiao, K. Muelling, J. M. Dolan, P. Palanisamy and P. Mudalige, “POMDP and Hierarchical Options MDP with Continuous Actions for Autonomous Driving at Intersections,” 2018 IEEE 21st International Conference on Intelligent Transportation Systems, Maui, 2018"
  link: https://praveenp.com/wp-content/uploads/2013/09/POMDP_Hierarchical_Options_MDP_with_Continuous_Actions_for_Autonomous_Driving_at_Intersections_ITSC2018_.pdf

- timeline-item:
  date: October 31, 2018
  title: "GM Award for invention – Vehicle state estimation failure detection using Deep Learning"
  img: TMS_apparatusMethodologyDLStateEstFailureDet-768x651.jpg
  description: "GM award for protected (secret) method invention: “Apparatus and Methodology for Deep Learning Based State Estimation Failure Detection”, 2017"

- timeline-item:
  date: October 29, 2018
  title: "3rd rank – Full Stack Deep Learning certification exam"
  img: FSDL_cert_completion_3rdRank-1-768x339.png
  description: "What was it?: Hands-on program for developers familiar with the basics of deep learning <br/> When was it?: August 3 – 5, UC Berkeley, CA. I scored 119 out of 124 which was the 3rd highest score. The certification exam statistics: <br/> Minimum: 23.0; Maximum: 124.0; Mean: 100.75; Median: 105.0; Standard Deviation: 20.54 <br/>The certification exam tested the following topics:Fundamentals of Deep Learning, Convnets, Sequences, Vision Applications, Troubleshooting Deep Learning implementations, Deep Learning Infrastructure, Deep Learning model deployment"

- timeline-item:
  date: June 26, 2019
  title: "[IV18]Automatic Curriculum Generation for RL in Autonomous Vehicles in Urban Environment"
  img: AGCS-768x380.png
  description: "We address the problem of learning autonomous driving behaviors in urban intersections using deep reinforcement learning (DRL). DRL has become a popular choice for creating autonomous agents due to its success in various tasks. However, as the problems tackled become more complex, the number of training iterations necessary increase drastically. Curriculum learning has been shown to reduce the required training time and improve the performance of the agent, but creating an optimal curriculum often requires human handcrafting. In this work, we learn a policy for urban intersection crossing using DRL and introduce a method to automatically generate the curriculum for the training process from a candidate set of tasks. We compare the performance of the automatically generated curriculum (AGC) training to those of randomly generated sequences and show that AGC can significantly reduce the training time while achieving similar or better performance. keywords: {learning (artificial intelligence);mobile robots;optimal curriculum;human handcrafting;urban intersection crossing;DRL;training process;automatically generated curriculum training;randomly generated sequences;autonomous vehicles;urban environment;autonomous driving behaviors;urban intersections;deep reinforcement learning;autonomous agents;training iterations necessary increase;curriculum learning;required training time;AGC;Training;Autonomous vehicles;Task analysis;Learning (artificial intelligence);Machine learning;Heuristic algorithms}, Citing: Z. Qiao, K. Muelling, J. M. Dolan, P. Palanisamy and P. Mudalige, “Automatically Generated Curriculum based Reinforcement Learning for Autonomous Vehicles in Urban Environment,” 2018 IEEE Intelligent Vehicles Symposium (IV), Changshu, 2018, pp. 1233-1238. doi: 10.1109/IVS.2018.8500603"
  link: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8500603&isnumber=8500355

- timeline-item:
  date: June 26, 2018
  title: "[IV18]Learning Vehicle Surrounding-aware Lane-changing Behavior from Observed Trajectories"
  img: IV18surroundingAwareLC.png
  description: "Predicting lane-changing intentions has long been a very active area of research in the autonomous driving community. However, most of the literature has focused on individual vehicles and did not consider both the neighbor information and the accumulated effects of vehicle history trajectories when making the predictions. We propose to apply a surrounding-aware LSTM algorithm for predicting the intention of a vehicle to perform a lane change that takes advantage of both vehicle past trajectories and their neighbor’s current states. We trained the model on real-world lane changing data and were able to show in simulation that these two components can lead not only to higher accuracy, but also to earlier lane-changing prediction time, which plays an important role in potentially improving the autonomous vehicle’s overall performance. keywords: {mobile robots;road safety;road vehicles;vehicle surrounding-aware lane-changing behavior;autonomous driving community;vehicle history trajectories;surrounding-aware LSTM algorithm;autonomous vehicle;lane-changing prediction time;lane-changing intentions;Trajectory;History;Prediction algorithms;Automobiles;Training;Predictive models;Feature extraction;LSTM;lane-change intention}, Citing: S. Su, K. Muelling, J. Dolan, P. Palanisamy and P. Mudalige, “Learning Vehicle Surrounding-aware Lane-changing Behavior from Observed Trajectories,” 2018 IEEE Intelligent Vehicles Symposium (IV), Changshu, 2018, pp. 1412-1417. doi: 10.1109/IVS.2018.8500445"
  link: http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8500445&isnumber=8500355
